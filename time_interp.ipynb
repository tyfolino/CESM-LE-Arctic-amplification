{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functioning-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Interpolate the monthly-average CAM5 kernels to daily resolution.\n",
    "\n",
    "# By: Ty Janoski\n",
    "# Updated: 06.08.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4bf185-16ca-41d7-94b0-32bbf4779231",
   "metadata": {},
   "source": [
    "## Interpolate Pendergrass CAM5 kernels from monthly -> daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comprehensive-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statments\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import nc_time_axis\n",
    "import scipy as sp\n",
    "from cftime import DatetimeNoLeap\n",
    "import scipy.io as io\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exotic-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to add a normalization factor to the q kernels\n",
    "norm = io.loadmat('/dx05/janoski/d10/Arctic_Research/cesm-LE/output/cam5-kernels/CAM5_qkernel_normfactor.mat')['dlogqdt']\n",
    "norm = norm.transpose([3,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adapted-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for reading in cesm-LE output\n",
    "# note: each ensemble member starts on january of a different year\n",
    "# please keep this in mind when combining datasets\n",
    "def read_in(exp,mon,ens,var):\n",
    "    \"\"\"\n",
    "    Use xarray to read in a netCDF file.\n",
    "\n",
    "    Keyword arguments:\n",
    "    exp -- CO2 scenario\n",
    "    mon -- starting month in which CO2 is altered\n",
    "    ens -- ensemble number\n",
    "    var -- model output variable\n",
    "    \"\"\"\n",
    "    filein = '/dx05/janoski/d10/Arctic_Research/cesm-LE/output/b40.1850.cam5-lens.'+exp+'.'+str(\n",
    "        f\"{mon:02d}\")+'.'+str(f\"{ens:02d}\")+'.h1_'+var+'.nc'\n",
    "    return(xr.open_dataset(filein,chunks=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alb.kernel\n",
      "PS\n",
      "q.kernel\n",
      "t.kernel\n",
      "ts.kernel\n"
     ]
    }
   ],
   "source": [
    "# make the midpoints\n",
    "midpoints = [DatetimeNoLeap(1,1,15,12),DatetimeNoLeap(1,2,14,0),\n",
    "            DatetimeNoLeap(1,3,15,12),DatetimeNoLeap(1,4,15,0),\n",
    "            DatetimeNoLeap(1,5,15,12),DatetimeNoLeap(1,6,15,0),\n",
    "            DatetimeNoLeap(1,7,15,12),DatetimeNoLeap(1,8,15,12),\n",
    "            DatetimeNoLeap(1,9,15,0),DatetimeNoLeap(1,10,15,12),\n",
    "            DatetimeNoLeap(1,11,15,0),DatetimeNoLeap(1,12,15,12)]\n",
    "# make new dates \n",
    "dates = xr.cftime_range(start=\"0001-01-01 12:00:00\",end=\"0001-12-31 12:00:00\",freq='D',calendar='noleap')\n",
    "# file endings\n",
    "files = ['alb.kernel','PS','q.kernel','t.kernel','ts.kernel']\n",
    "for f in files:\n",
    "    print(f)\n",
    "    # read in kernels\n",
    "    kern = xr.open_dataset('/dx05/janoski/d10/Arctic_Research/cesm-LE/output/cam5-kernels/kernels/'+f+'.nc',use_cftime=True)\n",
    "    \n",
    "    # overwrite time axis\n",
    "    kern['time'] = midpoints\n",
    "    \n",
    "    # we need to include a normalization factor in the q kernel\n",
    "    if(f=='q.kernel'):\n",
    "        kern['FLNS'] = kern.FLNS/norm\n",
    "        kern['FLNSC'] = kern.FLNSC/norm\n",
    "        kern['FLNT'] = kern.FLNT/norm\n",
    "        kern['FLNTC'] = kern.FLNTC/norm\n",
    "        kern['FSNS'] = kern.FSNS/norm\n",
    "        kern['FSNSC'] = kern.FSNSC/norm\n",
    "        kern['FSNT'] = kern.FSNT/norm\n",
    "        kern['FSNTC'] = kern.FSNTC/norm\n",
    "    \n",
    "    # slight issue: we want the daily kernels to be periodic (so that there is no discontinuity between Dec 31st and Jan 1st)\n",
    "    # we will have to \"pad\" with a preceding decemeber and succeeding January\n",
    "    pre = kern.isel(time=11)\n",
    "    pre['time'] = DatetimeNoLeap(0,12,15,12)\n",
    "\n",
    "    suc = kern.isel(time=0)\n",
    "    suc['time'] = DatetimeNoLeap(2,1,15,12)\n",
    "    \n",
    "    kern_extend = xr.concat([pre,kern,suc],dim='time')\n",
    "    \n",
    "    # interpolate (linear)\n",
    "    out = kern_extend.interp(time=dates,method='linear')\n",
    "    path = '/dx05/janoski/d10/Arctic_Research/cesm-LE/daily_kernels/'+f+'.nc'\n",
    "    \n",
    "    # save out\n",
    "    out.to_netcdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2790da-c09f-4b40-b86c-aa3030b766c9",
   "metadata": {},
   "source": [
    "## We are going to repeat the process for the CAM4 and CAM5 stratosphere-adjusted forcings.\n",
    "\n",
    "### CAM4 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65143ec5-2457-47f3-9fec-45fbf7e6241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the midpoints\n",
    "midpoints = [DatetimeNoLeap(2,1,15,12),DatetimeNoLeap(2,2,14,0),\n",
    "            DatetimeNoLeap(2,3,15,12),DatetimeNoLeap(2,4,15,0),\n",
    "            DatetimeNoLeap(2,5,15,12),DatetimeNoLeap(2,6,15,0),\n",
    "            DatetimeNoLeap(2,7,15,12),DatetimeNoLeap(2,8,15,12),\n",
    "            DatetimeNoLeap(2,9,15,0),DatetimeNoLeap(2,10,15,12),\n",
    "            DatetimeNoLeap(2,11,15,0),DatetimeNoLeap(2,12,15,12)]\n",
    "\n",
    "# make new dates \n",
    "dates = xr.cftime_range(start=\"0002-01-01 12:00:00\",end=\"0002-12-31 12:00:00\",freq='D',calendar='noleap')\n",
    "\n",
    "mon_avgs = []\n",
    "# read in CAM4 files\n",
    "for i in range(1,13,1):\n",
    "    # add leading 0\n",
    "    month = str(i).zfill(2)\n",
    "    \n",
    "    # read in file\n",
    "    file_in = xr.open_dataset('/dx01/chiodo/data4/port/f1850.cam.port.4xCO2.adj.001/cam4.4xco2.forcing.'+month+'.nc')\n",
    "    \n",
    "    # overwrite time axis on file\n",
    "    file_in['time'] = midpoints[i-1]\n",
    "    \n",
    "    # append to list\n",
    "    mon_avgs.append(file_in)\n",
    "    \n",
    "# as before, we need to add on leading and trailing month for boundary conditions in interpolation\n",
    "pre = mon_avgs[-1].copy()\n",
    "pre['time'] = DatetimeNoLeap(1,12,15,12)\n",
    "suc = mon_avgs[0].copy()\n",
    "suc['time'] = DatetimeNoLeap(3,1,15,12)\n",
    "mon_avgs.insert(0,pre)\n",
    "mon_avgs.append(suc)\n",
    "\n",
    "# turn list to dataset of montly averages\n",
    "monthly = xr.concat(mon_avgs,dim='time')\n",
    "\n",
    "# interpolate\n",
    "CAM4_daily = monthly.interp(time=dates,method='linear')\n",
    "path = '/dx02/janoski/cesm-LE/strat_adj_rf/CAM4_CAMRT_strat_adj_RF.nc'\n",
    "\n",
    "CAM4_daily.to_netcdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e6fc2-6af6-4fdb-8858-944288487176",
   "metadata": {},
   "source": [
    "### CAM5 RRTMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fc5b4d-6b3f-4c4a-9b33-6d43402c6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the midpoints\n",
    "midpoints = [DatetimeNoLeap(2,1,15,12),DatetimeNoLeap(2,2,14,0),\n",
    "            DatetimeNoLeap(2,3,15,12),DatetimeNoLeap(2,4,15,0),\n",
    "            DatetimeNoLeap(2,5,15,12),DatetimeNoLeap(2,6,15,0),\n",
    "            DatetimeNoLeap(2,7,15,12),DatetimeNoLeap(2,8,15,12),\n",
    "            DatetimeNoLeap(2,9,15,0),DatetimeNoLeap(2,10,15,12),\n",
    "            DatetimeNoLeap(2,11,15,0),DatetimeNoLeap(2,12,15,12)]\n",
    "\n",
    "# make new dates \n",
    "dates = xr.cftime_range(start=\"0002-01-01 12:00:00\",end=\"0002-12-31 12:00:00\",freq='D',calendar='noleap')\n",
    "\n",
    "mon_avgs = []\n",
    "# read in CAM4 files\n",
    "for i in range(1,13,1):\n",
    "    # add leading 0\n",
    "    month = str(i).zfill(2)\n",
    "    \n",
    "    # read in file\n",
    "    file_in = xr.open_dataset('/dx01/chiodo/data4/port/PCCAM5.e122.beta.f19_f19.4xCO2.001/cam5.4xco2.forcing.'+month+'.nc')\n",
    "    \n",
    "    # overwrite time axis on file\n",
    "    file_in['time'] = midpoints[i-1]\n",
    "    \n",
    "    # append to list\n",
    "    mon_avgs.append(file_in)\n",
    "    \n",
    "# as before, we need to add on leading and trailing month for boundary conditions in interpolation\n",
    "pre = mon_avgs[-1].copy()\n",
    "pre['time'] = DatetimeNoLeap(1,12,15,12)\n",
    "suc = mon_avgs[0].copy()\n",
    "suc['time'] = DatetimeNoLeap(3,1,15,12)\n",
    "mon_avgs.insert(0,pre)\n",
    "mon_avgs.append(suc)\n",
    "\n",
    "# # turn list to dataset of montly averages\n",
    "monthly = xr.concat(mon_avgs,dim='time')\n",
    "\n",
    "# # interpolate\n",
    "CAM5_daily = monthly.interp(time=dates,method='linear')\n",
    "path = '/dx02/janoski/cesm-LE/strat_adj_rf/CAM5_RRTMG_strat_adj_RF.nc'\n",
    "\n",
    "CAM5_daily.to_netcdf(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
